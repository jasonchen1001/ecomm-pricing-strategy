import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from data_preprocessing import load_data, extract_features
from price_elasticity import PriceElasticityAnalyzer
from sentiment_analysis import SentimentAnalyzer
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
from wordcloud import WordCloud
from nltk.corpus import opinion_lexicon
import nltk

# å¿…é¡»æ˜¯ç¬¬ä¸€ä¸ª Streamlit å‘½ä»¤
st.set_page_config(page_title="Amazon Product Analysis", layout="wide")

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
    <style>
    .main {
        padding: 2rem;
    }
    .stMetric {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
    }
    .stPlotly {
        background-color: white;
        padding: 1rem;
        border-radius: 0.5rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    h1 {
        color: #1f77b4;
        padding-bottom: 1rem;
        border-bottom: 2px solid #1f77b4;
    }
    h2 {
        color: #2c3e50;
        margin-top: 2rem;
    }
    </style>
""", unsafe_allow_html=True)

# ç¡®ä¿ä¸‹è½½å¿…è¦çš„è¯å…¸
try:
    nltk.data.find('corpora/opinion_lexicon')
except LookupError:
    nltk.download('opinion_lexicon')

def normalize_sizes(sizes, min_size=8, max_size=40):
    """å°†è¯äº‘å­—ä½“å¤§å°å½’ä¸€åŒ–åˆ°åˆç†èŒƒå›´"""
    if len(sizes) == 0:
        return []
    min_val = min(sizes)
    max_val = max(sizes)
    if max_val == min_val:
        return [max_size] * len(sizes)
    return [min_size + (max_size - min_size) * (s - min_val) / (max_val - min_val) for s in sizes]

def get_color_gradient(word=None, font_size=None, position=None, orientation=None, font_path=None, random_state=None):
    """ä¸ºè¯äº‘ç”Ÿæˆæ¸å˜è‰²"""
    # ä¸ºç§¯æè¯„è®ºä½¿ç”¨ç»¿è‰²æ¸å˜
    positive_colors = ['#90EE90', '#32CD32', '#228B22', '#006400']  # æµ…ç»¿åˆ°æ·±ç»¿
    # ä¸ºæ¶ˆæè¯„è®ºä½¿ç”¨çº¢è‰²æ¸å˜
    negative_colors = ['#FFB6C1', '#FF6B6B', '#DC143C', '#8B0000']  # æµ…çº¢åˆ°æ·±çº¢
    
    # æ ¹æ®å­—ä½“å¤§å°é€‰æ‹©é¢œè‰²
    colors = positive_colors if random_state.randint(2) == 0 else negative_colors
    color_idx = int(font_size * (len(colors) - 1) / 100)
    return colors[min(color_idx, len(colors) - 1)]

def create_wordcloud(text, title, sentiment_type='positive'):
    """åˆ›å»ºè¯äº‘å›¾"""
    # è·å–NLTKçš„æƒ…æ„Ÿè¯å…¸
    positive_words = set(opinion_lexicon.positive())
    negative_words = set(opinion_lexicon.negative())
    
    # äº§å“è¯„è®ºç‰¹å®šçš„ç§¯æè¯
    product_specific_positive = {
        'affordable', 'worth', 'sturdy', 'durable', 'reliable', 
        'fast', 'quick', 'solid', 'perfect', 'excellent',
        'strong', 'stable', 'premium', 'professional', 'recommended',
        'satisfied', 'quality', 'great', 'nice', 'good',
        'convenient', 'efficient', 'effective', 'impressive'
    }
    
    # äº§å“è¯„è®ºç‰¹å®šçš„æ¶ˆæè¯
    product_specific_negative = {
        'defective', 'faulty', 'broken', 'useless',
        'disappointing', 'terrible', 'horrible', 'awful',
        'worthless', 'poor-quality', 'unreliable', 'unstable',
        'overpriced', 'ineffective', 'malfunctioning',
        'negative', 'strain'
    }
    
    # éœ€è¦ç§»é™¤çš„æ­§ä¹‰è¯
    ambiguous_words = {
        'quality',    # å¯èƒ½è¡¨ç¤ºå¥½(ç§¯æ)æˆ–å·®(æ¶ˆæ)
        'cheap',      # å¯èƒ½è¡¨ç¤ºä¾¿å®œ(ç§¯æ)æˆ–åŠ£è´¨(æ¶ˆæ)
        'hard',       # å¯èƒ½è¡¨ç¤ºåšç¡¬(ç§¯æ)æˆ–å›°éš¾(æ¶ˆæ)
        'emergency',  # æè¿°æƒ…å†µè€Œéäº§å“è´¨é‡
        'blame',      # æè¿°è¡Œä¸ºè€Œéäº§å“
        'basic',      # å¯èƒ½æ˜¯ä¸­æ€§æè¿°
        'simple',     # å¯èƒ½æ˜¯ç§¯ææˆ–æ¶ˆæ
        'just',       # é€šå¸¸æ˜¯ä¸­æ€§è¯
        'want',       # æ„æ„¿æè¿°
        'need',       # éœ€æ±‚æè¿°
        'try',        # è¡Œä¸ºæè¿°
        'return',     # è¡Œä¸ºæè¿°
        'cost',       # ä»·æ ¼æè¿°
        'price',      # ä»·æ ¼æè¿°
        'charge'      # å¯èƒ½æ˜¯å……ç”µæˆ–æ”¶è´¹
    }
    
    # åœç”¨è¯
    stop_words = {
        'issues', 'issue', 'problem', 'problems',  # ä¸­æ€§è¯
        'like', 'well', 'better', 'works', 'work',  # ä¸­æ€§/æè¿°æ€§è¯
        'cable', 'charger', 'wire', 'cord', 'adapter',  # äº§å“ç›¸å…³è¯
        'time', 'month', 'day', 'year', 'week',  # æ—¶é—´ç›¸å…³è¯
        'amazon', 'product', 'purchase', 'bought', 'order',  # è´­ä¹°ç›¸å…³è¯
        'use', 'using', 'used', 'usage',  # ä½¿ç”¨ç›¸å…³è¯
        'one', 'two', 'three', 'first', 'second',  # æ•°å­—ç›¸å…³è¯
        'the', 'and', 'for', 'that', 'this', 'with',  # å¸¸è§åœç”¨è¯
        'was', 'is', 'are', 'were', 'been', 'be', 'have'
    }
    
    # æ›´æ–°æƒ…æ„Ÿè¯å…¸
    positive_words.update(product_specific_positive)
    negative_words.update(product_specific_negative)
    
    # ç§»é™¤æ­§ä¹‰è¯å’Œåœç”¨è¯
    positive_words = positive_words - ambiguous_words - stop_words
    negative_words = negative_words - ambiguous_words - stop_words
    
    # åˆ†è¯å¹¶è¿‡æ»¤
    words = text.lower().split()
    if sentiment_type == 'positive':
        filtered_words = [word for word in words 
                         if word in positive_words]
        colormap = 'YlGn'
    else:
        filtered_words = [word for word in words 
                         if word in negative_words]
        colormap = 'RdPu'
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æƒ…æ„Ÿè¯ï¼Œè¿”å›ç©ºå›¾
    if not filtered_words:
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.text(0.5, 0.5, 'No significant sentiment words found',
                ha='center', va='center')
        ax.axis('off')
        return fig
    
    # ç”Ÿæˆè¯äº‘
    text = ' '.join(filtered_words)
    wordcloud = WordCloud(
        width=800,
        height=400,
        background_color='white',
        colormap=colormap,
        max_words=30,
        min_font_size=12,
        max_font_size=160,
        prefer_horizontal=0.7
    ).generate(text)
    
    # åˆ›å»ºå›¾å½¢ä½†ä¸æ·»åŠ æ ‡é¢˜
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    return fig

def get_top_sentiment_words(text, sentiment_type='positive', n=10):
    """è·å–å‰Nä¸ªæœ€å¸¸è§çš„æƒ…æ„Ÿè¯"""
    # è·å–æƒ…æ„Ÿè¯å…¸
    positive_words = set(opinion_lexicon.positive())
    negative_words = set(opinion_lexicon.negative())
    
    # äº§å“è¯„è®ºç‰¹å®šçš„ç§¯æè¯
    product_specific_positive = {
        'affordable', 'worth', 'sturdy', 'durable', 'reliable', 
        'fast', 'quick', 'solid', 'perfect', 'excellent',
        'strong', 'stable', 'premium', 'professional', 'recommended',
        'satisfied', 'quality', 'great', 'nice', 'good',
        'convenient', 'efficient', 'effective', 'impressive'
    }
    
    # äº§å“è¯„è®ºç‰¹å®šçš„æ¶ˆæè¯ï¼ˆåªä¿ç•™æ˜ç¡®çš„è´Ÿé¢è¯ï¼‰
    product_specific_negative = {
        'defective', 'faulty', 'broken', 'useless',
        'disappointing', 'terrible', 'horrible', 'awful',
        'worthless', 'poor-quality', 'unreliable', 'unstable',
        'overpriced', 'ineffective', 'malfunctioning'
    }
    
    # éœ€è¦ä»æƒ…æ„Ÿè¯å…¸ä¸­ç§»é™¤çš„æ­§ä¹‰è¯
    ambiguous_words = {
        'quality',    # å¯èƒ½è¡¨ç¤ºä¾¿å®œ(ç§¯æ)æˆ–åŠ£è´¨(æ¶ˆæ)
        'cheap',      # å¯èƒ½è¡¨ç¤ºä¾¿å®œ(ç§¯æ)æˆ–åŠ£è´¨(æ¶ˆæ)
        'hard',       # å¯èƒ½è¡¨ç¤ºåšç¡¬(ç§¯æ)æˆ–å›°éš¾(æ¶ˆæ)
        'emergency',  # æè¿°æƒ…å†µè€Œéäº§å“è´¨é‡
        'blame',      # æè¿°è¡Œä¸ºè€Œéäº§å“
        'basic',      # å¯èƒ½æ˜¯ä¸­æ€§æè¿°
        'simple',     # å¯èƒ½æ˜¯ç§¯ææˆ–æ¶ˆæ
        'just',       # é€šå¸¸æ˜¯ä¸­æ€§è¯
        'want',       # æ„æ„¿æè¿°
        'need',       # éœ€æ±‚æè¿°
        'try',        # è¡Œä¸ºæè¿°
        'return',     # è¡Œä¸ºæè¿°
        'cost',       # ä»·æ ¼æè¿°
        'price',      # ä»·æ ¼æè¿°
        'charge'      # å¯èƒ½æ˜¯å……ç”µæˆ–æ”¶è´¹
    }
    
    # é¢å¤–çš„åœç”¨è¯
    extra_stop_words = {
        'issues', 'issue', 'problem', 'problems',  # ä¸­æ€§è¯
        'like', 'well', 'better', 'works', 'work',  # ä¸­æ€§/æè¿°æ€§è¯
        'cable', 'charger', 'wire', 'cord', 'adapter',  # äº§å“ç›¸å…³è¯
        'time', 'month', 'day', 'year', 'week',  # æ—¶é—´ç›¸å…³è¯
        'amazon', 'product', 'purchase', 'bought', 'order',  # è´­ä¹°ç›¸å…³è¯
        'use', 'using', 'used', 'usage',  # ä½¿ç”¨ç›¸å…³è¯
        'one', 'two', 'three', 'first', 'second',  # æ•°å­—ç›¸å…³è¯
    }
    
    # æ›´æ–°æƒ…æ„Ÿè¯å…¸
    positive_words.update(product_specific_positive)
    negative_words.update(product_specific_negative)
    
    # ç§»é™¤æ‰€æœ‰æ­§ä¹‰è¯å’Œåœç”¨è¯
    positive_words = positive_words - ambiguous_words - extra_stop_words
    negative_words = negative_words - ambiguous_words - extra_stop_words
    
    # åˆ†è¯å¹¶è¿‡æ»¤
    words = text.lower().split()
    word_freq = {}
    target_words = positive_words if sentiment_type == 'positive' else negative_words
    
    for word in words:
        if word in target_words:
            word_freq[word] = word_freq.get(word, 0) + 1
    
    # è·å–å‰Nä¸ªæœ€å¸¸è§çš„è¯
    top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:n]
    return top_words

def get_display_text(en_text, zh_text, lang='en'):
    """æ ¹æ®é€‰æ‹©çš„è¯­è¨€è¿”å›æ˜¾ç¤ºæ–‡æœ¬"""
    return en_text if lang == 'en' else zh_text

def main():
    # æ·»åŠ è¯­è¨€é€‰æ‹©å™¨åˆ°ä¾§è¾¹æ 
    lang = st.sidebar.selectbox(
        "Language / è¯­è¨€",
        options=['en', 'zh'],
        format_func=lambda x: "English" if x == 'en' else "ä¸­æ–‡"
    )
    
    try:
        df = load_data('amazon.csv')
    except Exception as e:
        st.error(get_display_text(
            'Error loading data: Please check if amazon.csv exists in the correct location.',
            'åŠ è½½æ•°æ®é”™è¯¯ï¼šè¯·æ£€æŸ¥ amazon.csv æ–‡ä»¶æ˜¯å¦å­˜åœ¨äºæ­£ç¡®ä½ç½®ã€‚',
            lang
        ))
        st.exception(e)
        return
    
    st.title(get_display_text(
        'ğŸ›ï¸ Amazon Product Analysis Dashboard',
        'ğŸ›ï¸ äºšé©¬é€Šäº§å“åˆ†æä»ªè¡¨æ¿',
        lang
    ))
    
    # Market Overview éƒ¨åˆ†ç§»åˆ°è¿™é‡Œ
    st.header(get_display_text('ğŸ“Š Market Overview', 'ğŸ“Š å¸‚åœºæ¦‚è§ˆ', lang))
    
    # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            get_display_text("Total Products", "äº§å“æ€»æ•°", lang),
            f"{len(df):,}"
        )
    
    with col2:
        avg_rating = df['rating'].mean()
        st.metric(
            get_display_text("Average Rating", "å¹³å‡è¯„åˆ†", lang),
            f"{avg_rating:.2f} â­"
        )
    
    with col3:
        avg_price = df['discounted_price'].mean()
        st.metric(
            get_display_text("Average Price", "å¹³å‡ä»·æ ¼", lang),
            f"â‚¹{avg_price:.2f}"
        )
    
    with col4:
        avg_discount = df['real_discount'].mean()
        st.metric(
            get_display_text("Average Discount", "å¹³å‡æŠ˜æ‰£", lang),
            f"{avg_discount:.1f}%"
        )
    
    # åˆ›å»ºæ ‡ç­¾é¡µ - è°ƒæ•´é¡ºåº
    tab1, tab2, tab3 = st.tabs([
        get_display_text('Price Analysis', 'ä»·æ ¼åˆ†æ', lang),
        get_display_text('Review Analysis', 'è¯„è®ºåˆ†æ', lang),
        get_display_text('Product Rankings', 'äº§å“æ’å', lang)
    ])
    
    # åŠ è½½æ•°æ®æ—¶æ˜¾ç¤ºè¿›åº¦æ¡
    with st.spinner('Loading data...'):
        df, features, analyzer = load_cached_data()
    
    # åˆ›å»ºä»·æ ¼å¼¹æ€§åˆ†æå™¨å®ä¾‹
    elasticity_analyzer = PriceElasticityAnalyzer()
    
    # ä¾§è¾¹æ ä¼˜åŒ–
    st.sidebar.image('https://upload.wikimedia.org/wikipedia/commons/4/4a/Amazon_icon.svg', width=100)
    st.sidebar.title('Analysis Controls')
    
    # ç®€åŒ–ä¾§è¾¹æ è®¾ç½®
    st.sidebar.markdown("---")
    st.sidebar.subheader("Price Elasticity Settings")
    
    # åªä¿ç•™å¼¹æ€§ç³»æ•°è®¡ç®—æ–¹æ³•é€‰æ‹©
    elasticity_method = st.sidebar.selectbox(
        'Calculation Method',
        ['Log-Log', 'Point', 'Arc'],
        help="Method to calculate price elasticity"
    )
    
    # æ·»åŠ æ›´å¤šç­›é€‰å™¨
    price_range = st.sidebar.slider(
        'Price Range (â‚¹)',
        float(df['discounted_price'].min()),
        float(df['discounted_price'].max()),
        (float(df['discounted_price'].min()), float(df['discounted_price'].max()))
    )
    
    rating_filter = st.sidebar.slider(
        'Minimum Rating',
        min_value=0.0,
        max_value=5.0,
        value=0.0,
        step=0.5
    )
    
    # æ•°æ®ç­›é€‰
    mask = (
        (df['discounted_price'] >= price_range[0]) & 
        (df['discounted_price'] <= price_range[1]) &
        (df['rating'] >= rating_filter)
    )
    filtered_df = df[mask]
    
    # æ·»åŠ åˆ·æ–°æŒ‰é’®
    if st.sidebar.button('Refresh Analysis'):
        try:
            st.rerun()
        except AttributeError:
            try:
                st.experimental_rerun()  # å…¼å®¹æ—§ç‰ˆæœ¬
            except AttributeError:
                st.error("Refresh functionality not available in this Streamlit version")
    
    # ä½¿ç”¨tabsç»„ç»‡å†…å®¹
    with tab1:
        # Price Analysis å†…å®¹
        st.header(get_display_text('ğŸ’° Price Analysis', 'ğŸ’° ä»·æ ¼åˆ†æ', lang))
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader('Price Distribution')
            fig = px.histogram(
                filtered_df,
                x='discounted_price',
                nbins=30,
                title='Price Distribution',
                labels={'discounted_price': 'Price (â‚¹)', 'count': 'Count'},
                hover_data=['discounted_price'],
                opacity=0.7,  # è°ƒæ•´é€æ˜åº¦
            )
            
            # æ›´æ–°å›¾è¡¨å¸ƒå±€
            fig.update_layout(
                bargap=0.2,  # æ·»åŠ æŸ±å­ä¹‹é—´çš„é—´éš”
                plot_bgcolor='white',  # è®¾ç½®ç™½è‰²èƒŒæ™¯
                showlegend=False,
                xaxis=dict(
                    title='Price (â‚¹)',
                    gridcolor='lightgrey',
                    showgrid=True,
                    showline=True,
                    linewidth=1,
                    linecolor='black',
                    tickformat='â‚¹%d'
                ),
                yaxis=dict(
                    title='Number of Products',
                    gridcolor='lightgrey',
                    showgrid=True,
                    showline=True,
                    linewidth=1,
                    linecolor='black'
                ),
                margin=dict(l=40, r=40, t=40, b=40)  # è°ƒæ•´è¾¹è·
            )
            
            # æ›´æ–°æŸ±å­é¢œè‰²å’Œè¾¹æ¡†
            fig.update_traces(
                marker_color='rgb(30, 144, 255)',  # è®¾ç½®æŸ±å­é¢œè‰²ä¸ºæ·±è“è‰²
                marker_line_color='rgb(8, 48, 107)',  # è®¾ç½®è¾¹æ¡†é¢œè‰²
                marker_line_width=1  # è®¾ç½®è¾¹æ¡†å®½åº¦
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # æ·»åŠ ç›¸å…³æ€§åˆ†æ
            st.subheader('ğŸ“Š Correlation Analysis')
            correlation_matrix = filtered_df[
                ['discounted_price', 'rating', 'rating_count', 'real_discount']
            ].corr()
            
            labels = {
                'discounted_price': 'Price',
                'rating': 'Rating',
                'rating_count': 'Reviews',
                'real_discount': 'Discount'
            }
            
            fig = go.Figure(data=go.Heatmap(
                z=correlation_matrix,
                x=list(labels.values()),
                y=list(labels.values()),
                text=correlation_matrix.round(2),
                texttemplate='%{text}',
                textfont={"size": 10},
                hoverongaps=False,
                hovertemplate='%{x} vs %{y}<br>Correlation: %{z:.2f}<extra></extra>',
                colorscale='RdBu',
                zmid=0
            ))
            
            fig.update_layout(
                title='Correlation Matrix',
                height=400,
                hoverlabel=dict(bgcolor="white"),
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.subheader('Price Elasticity Analysis')
            
            # è®¡ç®—ä»·æ ¼å¼¹æ€§ç³»æ•°
            elasticity = elasticity_analyzer.calculate_elasticity(
                filtered_df['discounted_price'].values,
                filtered_df['rating_count'].values,
                method=elasticity_method
            )
            
            # æ˜¾ç¤ºå¼¹æ€§ç³»æ•°åŠå…¶å«ä¹‰
            st.metric('Price Elasticity', f"{elasticity:.2f}")
            
            if elasticity < 0.5:
                st.success("""
                **ä½ä»·æ ¼å¼¹æ€§** (< 0.5):
                - æ¶ˆè´¹è€…å¯¹ä»·æ ¼å˜åŒ–ä¸æ•æ„Ÿ
                - å¯ä»¥è€ƒè™‘é€‚å½“æé«˜ä»·æ ¼
                - é‡ç‚¹å…³æ³¨äº§å“è´¨é‡å’Œå“ç‰Œå»ºè®¾
                """)
            else:
                st.warning("""
                **é«˜ä»·æ ¼å¼¹æ€§** (â‰¥ 0.5):
                - æ¶ˆè´¹è€…å¯¹ä»·æ ¼å˜åŒ–æ•æ„Ÿ
                - éœ€è¦è°¨æ…è°ƒæ•´ä»·æ ¼
                - å…³æ³¨ç«å“å®šä»·ç­–ç•¥
                """)
            
            # æ ¹æ®ä¸åŒçš„è®¡ç®—æ–¹æ³•æ˜¾ç¤ºä¸åŒçš„ä»·æ ¼-éœ€æ±‚å…³ç³»å›¾
            if elasticity_method == 'Log-Log':
                # å¯¹æ•°è½¬æ¢åçš„æ•£ç‚¹å›¾
                fig = px.scatter(
                    filtered_df,
                    x=np.log(filtered_df['discounted_price']),
                    y=np.log(filtered_df['rating_count']),
                    title='Log-Log Price vs Demand',
                    labels={
                        'x': 'Log Price',
                        'y': 'Log Demand'
                    },
                    trendline="ols"
                )
            elif elasticity_method == 'Point':
                # åˆ†æ®µç‚¹å¼¹æ€§å›¾
                fig = px.scatter(
                    filtered_df,
                    x='discounted_price',
                    y='rating_count',
                    title='Point Price Elasticity',
                    labels={
                        'discounted_price': 'Price (â‚¹)',
                        'rating_count': 'Demand (Reviews)'
                    }
                )
                # æ·»åŠ åˆ†æ®µç‚¹å¼¹æ€§çº¿
                sorted_df = filtered_df.sort_values('discounted_price')
                segments = np.array_split(sorted_df, 5)
                for segment in segments:
                    fig.add_trace(go.Scatter(
                        x=segment['discounted_price'],
                        y=segment['rating_count'],
                        mode='lines',
                        name=f'Segment {len(fig.data)}'
                    ))
            else:  # Arc
                # å¼§å¼¹æ€§å›¾
                fig = px.scatter(
                    filtered_df,
                    x='discounted_price',
                    y='rating_count',
                    title='Arc Price Elasticity',
                    labels={
                        'discounted_price': 'Price (â‚¹)',
                        'rating_count': 'Demand (Reviews)'
                    },
                    trendline="lowess"  # ä½¿ç”¨å±€éƒ¨åŠ æƒå›å½’
                )
            
            st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        # Review Analysis å†…å®¹
        st.header(get_display_text('ğŸ“ Review Analysis', 'ğŸ“ è¯„è®ºåˆ†æ', lang))
        
        # æ˜¾ç¤ºæƒ…æ„Ÿåˆ†å¸ƒæŒ‡æ ‡
        total_reviews = len(df)
        positive_count = (df['sentiment'] == 1.0).sum()
        neutral_count = (df['sentiment'] == 0.0).sum()
        negative_count = (df['sentiment'] == -1.0).sum()
        
        positive_ratio = (positive_count / total_reviews) * 100
        neutral_ratio = (neutral_count / total_reviews) * 100
        negative_ratio = (negative_count / total_reviews) * 100
        
        # ä½¿ç”¨åˆ—å¸ƒå±€æ˜¾ç¤ºæŒ‡æ ‡
        st.markdown(get_display_text("### Sentiment Distribution", "### è¯„è®ºæƒ…æ„Ÿåˆ†å¸ƒ", lang))
        metric_cols = st.columns(3)
        
        with metric_cols[0]:
            st.metric(
                get_display_text("Positive Reviews", "ç§¯æè¯„è®º", lang),
                f"{positive_ratio:.1f}%",
                get_display_text(f"{positive_count} reviews", f"{positive_count} æ¡è¯„è®º", lang)
            )
        
        with metric_cols[1]:
            st.metric(
                get_display_text("Neutral Reviews", "ä¸­æ€§è¯„è®º", lang),
                f"{neutral_ratio:.1f}%",
                get_display_text(f"{neutral_count} reviews", f"{neutral_count} æ¡è¯„è®º", lang)
            )
        
        with metric_cols[2]:
            st.metric(
                get_display_text("Negative Reviews", "æ¶ˆæè¯„è®º", lang),
                f"{negative_ratio:.1f}%",
                get_display_text(f"{negative_count} reviews", f"{negative_count} æ¡è¯„è®º", lang)
            )
        
        # æƒ…æ„Ÿè¯åˆ†æéƒ¨åˆ†
        st.markdown(get_display_text("### Sentiment Word Analysis", "### æƒ…æ„Ÿè¯åˆ†æ", lang))
        
        # è·å–æ­£é¢å’Œè´Ÿé¢è¯„è®ºçš„æ–‡æœ¬
        positive_text = ' '.join(df[df['sentiment'] == 1.0]['review_content'].astype(str))
        negative_text = ' '.join(df[df['sentiment'] == -1.0]['review_content'].astype(str))
        
        # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown(get_display_text("#### Positive Review Keywords", "#### ç§¯æè¯„è®ºå…³é”®è¯", lang))
            # è¯äº‘å›¾
            if positive_text:
                fig_pos = create_wordcloud(
                    positive_text,
                    get_display_text("Positive Reviews", "ç§¯æè¯„è®º", lang),
                    'positive'
                )
                st.pyplot(fig_pos)
            
            # ç§¯ææƒ…æ„Ÿè¯é¢‘ç‡ç›´æ–¹å›¾
            top_positive = get_top_sentiment_words(positive_text, 'positive', 10)
            if top_positive:
                # åˆ›å»ºæ¸å˜ç»¿è‰²ï¼ˆé¢‘æ¬¡é«˜çš„é¢œè‰²æ›´æ·±ï¼‰
                n_bars = len(top_positive)
                green_colors = [
                    f'rgba(40, {200 - i * 15}, 40, {1 - i * 0.05})'  # ä»æ·±åˆ°æµ…çš„ç»¿è‰²
                    for i in range(n_bars)
                ]
                
                fig_pos_freq = go.Figure()
                fig_pos_freq.add_trace(go.Bar(
                    x=[word for word, _ in top_positive],
                    y=[freq for _, freq in top_positive],
                    marker_color=green_colors,
                    hovertemplate=get_display_text(
                        'Word: %{x}<br>Frequency: %{y}',
                        'è¯è¯­: %{x}<br>é¢‘æ¬¡: %{y}',
                        lang
                    ) + '<extra></extra>'
                ))
                
                fig_pos_freq.update_layout(
                    title=get_display_text("Top 10 Positive Words", "å‰10ä¸ªç§¯æè¯", lang),
                    xaxis_title=get_display_text("Words", "è¯è¯­", lang),
                    yaxis_title=get_display_text("Frequency", "é¢‘æ¬¡", lang),
                    showlegend=False,
                    xaxis_tickangle=-45,
                    height=400,
                    plot_bgcolor='white',
                    yaxis=dict(gridcolor='rgba(0,0,0,0.1)'),
                    margin=dict(l=50, r=20, t=50, b=80)
                )
                st.plotly_chart(fig_pos_freq)
        
        with col2:
            st.markdown(get_display_text("#### Negative Review Keywords", "#### æ¶ˆæè¯„è®ºå…³é”®è¯", lang))
            # è¯äº‘å›¾
            if negative_text:
                fig_neg = create_wordcloud(
                    negative_text,
                    get_display_text("Negative Reviews", "æ¶ˆæè¯„è®º", lang),
                    'negative'
                )
                st.pyplot(fig_neg)
            
            # æ¶ˆææƒ…æ„Ÿè¯é¢‘ç‡ç›´æ–¹å›¾
            top_negative = get_top_sentiment_words(negative_text, 'negative', 10)
            if top_negative:
                # åˆ›å»ºæ¸å˜çº¢è‰²ï¼ˆé¢‘æ¬¡é«˜çš„é¢œè‰²æ›´æ·±ï¼‰
                n_bars = len(top_negative)
                red_colors = [
                    f'rgba({255 - i * 10}, {20 + i * 5}, {20 + i * 5}, {1 - i * 0.05})'  # ä»æ·±åˆ°æµ…çš„çº¢è‰²
                    for i in range(n_bars)
                ]
                
                fig_neg_freq = go.Figure()
                fig_neg_freq.add_trace(go.Bar(
                    x=[word for word, _ in top_negative],
                    y=[freq for _, freq in top_negative],
                    marker_color=red_colors,
                    hovertemplate=get_display_text(
                        'Word: %{x}<br>Frequency: %{y}',
                        'è¯è¯­: %{x}<br>é¢‘æ¬¡: %{y}',
                        lang
                    ) + '<extra></extra>'
                ))
                
                fig_neg_freq.update_layout(
                    title=get_display_text("Top 10 Negative Words", "å‰10ä¸ªæ¶ˆæè¯", lang),
                    xaxis_title=get_display_text("Words", "è¯è¯­", lang),
                    yaxis_title=get_display_text("Frequency", "é¢‘æ¬¡", lang),
                    showlegend=False,
                    xaxis_tickangle=-45,
                    height=400,
                    plot_bgcolor='white',
                    yaxis=dict(gridcolor='rgba(0,0,0,0.1)'),
                    margin=dict(l=50, r=20, t=50, b=80)
                )
                st.plotly_chart(fig_neg_freq)
        
        # è¯„åˆ†åˆ†å¸ƒ
        st.markdown(get_display_text("### Rating Distribution", "### è¯„åˆ†åˆ†å¸ƒ", lang))
        rating_counts = df['rating'].value_counts().sort_index()
        fig_rating = go.Figure()
        
        # æ·»åŠ æŸ±çŠ¶å›¾
        fig_rating.add_trace(go.Bar(
            x=rating_counts.index,
            y=rating_counts.values,
            marker_color='rgb(0, 123, 255)',
            hovertemplate=get_display_text('Rating: %{x}<br>Count: %{y}', 'è¯„åˆ†: %{x}<br>æ•°é‡: %{y}', lang) + '<extra></extra>'
        ))
        
        # æ›´æ–°å¸ƒå±€
        fig_rating.update_layout(
            title={
                'text': get_display_text('Rating Distribution', 'è¯„åˆ†åˆ†å¸ƒ', lang),
                'y': 0.9,
                'x': 0.5,
                'xanchor': 'center',
                'yanchor': 'top'
            },
            xaxis=dict(
                title=get_display_text('Rating', 'è¯„åˆ†', lang),
                tickmode='array',
                ticktext=['1', '2', '3', '4', '5'],
                tickvals=[1, 2, 3, 4, 5],
                tickangle=0,
                gridcolor='rgba(0,0,0,0.1)',
                showgrid=True
            ),
            yaxis=dict(
                title=get_display_text('Review Count', 'è¯„è®ºæ•°é‡', lang),
                gridcolor='rgba(0,0,0,0.1)',
                showgrid=True
            ),
            plot_bgcolor='white',
            showlegend=False,
            height=400,
            margin=dict(l=50, r=50, t=80, b=50),
            bargap=0.2
        )
        
        # æ·»åŠ å¹³å‡è¯„åˆ†æ ‡æ³¨
        avg_rating = df['rating'].mean()
        fig_rating.add_vline(
            x=avg_rating,
            line_dash="dash",
            line_color="red",
            annotation_text=get_display_text(f"Average Rating: {avg_rating:.2f}", f"å¹³å‡è¯„åˆ†: {avg_rating:.2f}", lang),
            annotation_position="top"
        )
        
        st.plotly_chart(fig_rating, use_container_width=True)
    
    with tab3:
        # Product Rankings å†…å®¹
        st.header(get_display_text('ğŸ† Product Rankings', 'ğŸ† äº§å“æ’å', lang))
        top_products = filtered_df.nlargest(10, 'rating')[
            ['product_name', 'discounted_price', 'rating', 'rating_count']
        ].reset_index(drop=True)
        
        # ä½¿ç”¨æ›´å¥½çš„è¡¨æ ¼å±•ç¤º
        st.dataframe(
            top_products,
            column_config={
                "product_name": "Product Name",
                "discounted_price": st.column_config.NumberColumn(
                    get_display_text("Price (â‚¹)", "ä»·æ ¼ (â‚¹)", lang),
                    format="â‚¹%.2f"
                ),
                "rating": st.column_config.NumberColumn(
                    get_display_text("Rating", "è¯„åˆ†", lang),
                    format="%.1f â­"
                ),
                "rating_count": st.column_config.NumberColumn(
                    get_display_text("Reviews", "è¯„è®º", lang),
                    format="%d ğŸ“"
                )
            },
            hide_index=True,
            use_container_width=True
        )
    
    # ç§»é™¤é¡µé¢åº•éƒ¨çš„ç›¸å…³æ€§çŸ©é˜µ
    # åªä¿ç•™é¡µè„š
    st.markdown("""---""")
    st.markdown("""
        <div style='text-align: center'>
            <p>Made with â¤ï¸ by Yanzhen Chen | Data last updated: 2025</p>
        </div>
    """, unsafe_allow_html=True)

# åŠ è½½æ•°æ®
@st.cache_data
def load_cached_data():
    df = load_data('amazon.csv')
    features = extract_features(df)
    
    # æƒ…æ„Ÿåˆ†æ
    analyzer = SentimentAnalyzer()
    df = analyzer.analyze_reviews(df)
    
    return df, features, analyzer

if __name__ == '__main__':
    main() 
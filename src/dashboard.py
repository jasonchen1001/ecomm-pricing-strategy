import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from data_preprocessing import load_data, extract_features
from price_elasticity import PriceElasticityAnalyzer
from sentiment_analysis import SentimentAnalyzer
import plotly.express as px
import plotly.graph_objects as go
import plotly.figure_factory as ff
import numpy as np
from sklearn.linear_model import LinearRegression
from wordcloud import WordCloud
from io import BytesIO
from nltk.corpus import opinion_lexicon
import nltk

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="Amazon Cable Products Analysis",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
    <style>
    .main {
        padding: 2rem;
    }
    .stMetric {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
    }
    .stPlotly {
        background-color: white;
        padding: 1rem;
        border-radius: 0.5rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    h1 {
        color: #1f77b4;
        padding-bottom: 1rem;
        border-bottom: 2px solid #1f77b4;
    }
    h2 {
        color: #2c3e50;
        margin-top: 2rem;
    }
    </style>
""", unsafe_allow_html=True)

# ç¡®ä¿ä¸‹è½½å¿…è¦çš„è¯å…¸
try:
    nltk.data.find('corpora/opinion_lexicon')
except LookupError:
    nltk.download('opinion_lexicon')

def normalize_sizes(sizes, min_size=8, max_size=40):
    """å°†è¯äº‘å­—ä½“å¤§å°å½’ä¸€åŒ–åˆ°åˆç†èŒƒå›´"""
    if len(sizes) == 0:
        return []
    min_val = min(sizes)
    max_val = max(sizes)
    if max_val == min_val:
        return [max_size] * len(sizes)
    return [min_size + (max_size - min_size) * (s - min_val) / (max_val - min_val) for s in sizes]

def get_color_gradient(word=None, font_size=None, position=None, orientation=None, font_path=None, random_state=None):
    """ä¸ºè¯äº‘ç”Ÿæˆæ¸å˜è‰²"""
    # ä¸ºç§¯æè¯„è®ºä½¿ç”¨ç»¿è‰²æ¸å˜
    positive_colors = ['#90EE90', '#32CD32', '#228B22', '#006400']  # æµ…ç»¿åˆ°æ·±ç»¿
    # ä¸ºæ¶ˆæè¯„è®ºä½¿ç”¨çº¢è‰²æ¸å˜
    negative_colors = ['#FFB6C1', '#FF6B6B', '#DC143C', '#8B0000']  # æµ…çº¢åˆ°æ·±çº¢
    
    # æ ¹æ®å­—ä½“å¤§å°é€‰æ‹©é¢œè‰²
    colors = positive_colors if random_state.randint(2) == 0 else negative_colors
    color_idx = int(font_size * (len(colors) - 1) / 100)
    return colors[min(color_idx, len(colors) - 1)]

def create_wordcloud(text, title, sentiment_type='positive'):
    """åˆ›å»ºè¯äº‘å›¾"""
    # è·å–NLTKçš„æƒ…æ„Ÿè¯å…¸
    positive_words = set(opinion_lexicon.positive())
    negative_words = set(opinion_lexicon.negative())
    
    # äº§å“è¯„è®ºç‰¹å®šçš„ç§¯æè¯
    product_specific_positive = {
        'affordable', 'worth', 'sturdy', 'durable', 'reliable', 
        'fast', 'quick', 'solid', 'perfect', 'excellent',
        'strong', 'stable', 'premium', 'professional', 'recommended',
        'satisfied', 'quality', 'great', 'nice', 'good',
        'convenient', 'efficient', 'effective', 'impressive'
    }
    
    # äº§å“è¯„è®ºç‰¹å®šçš„æ¶ˆæè¯
    product_specific_negative = {
        'defective', 'faulty', 'broken', 'useless',
        'disappointing', 'terrible', 'horrible', 'awful',
        'worthless', 'poor-quality', 'unreliable', 'unstable',
        'overpriced', 'ineffective', 'malfunctioning',
        'negative', 'strain'  
    }
    
    # éœ€è¦ç§»é™¤çš„æ­§ä¹‰è¯
    ambiguous_words = {
        'cheap',      # å¯èƒ½è¡¨ç¤ºä¾¿å®œ(ç§¯æ)æˆ–åŠ£è´¨(æ¶ˆæ)
        'quality',    # å¯èƒ½è¡¨ç¤ºä¾¿å®œ(ç§¯æ)æˆ–åŠ£è´¨(æ¶ˆæ)
        'hard',       # å¯èƒ½è¡¨ç¤ºåšç¡¬(ç§¯æ)æˆ–å›°éš¾(æ¶ˆæ)
        'emergency',  # æè¿°æƒ…å†µè€Œéäº§å“è´¨é‡
        'blame',      # æè¿°è¡Œä¸ºè€Œéäº§å“
        'basic',      # å¯èƒ½æ˜¯ä¸­æ€§æè¿°
        'simple',     # å¯èƒ½æ˜¯ç§¯ææˆ–æ¶ˆæ
        'just',       # é€šå¸¸æ˜¯ä¸­æ€§è¯
        'want',       # æ„æ„¿æè¿°
        'need',       # éœ€æ±‚æè¿°
        'try',        # è¡Œä¸ºæè¿°
        'return',     # è¡Œä¸ºæè¿°
        'cost',       # ä»·æ ¼æè¿°
        'price',      # ä»·æ ¼æè¿°
        'charge'      # å¯èƒ½æ˜¯å……ç”µæˆ–æ”¶è´¹
    }
    
    # åœç”¨è¯
    stop_words = {
        'issues', 'issue', 'problem', 'problems',  # ä¸­æ€§è¯
        'like', 'well', 'better', 'works', 'work',  # ä¸­æ€§/æè¿°æ€§è¯
        'cable', 'charger', 'wire', 'cord', 'adapter',  # äº§å“ç›¸å…³è¯
        'time', 'month', 'day', 'year', 'week',  # æ—¶é—´ç›¸å…³è¯
        'amazon', 'product', 'purchase', 'bought', 'order',  # è´­ä¹°ç›¸å…³è¯
        'use', 'using', 'used', 'usage',  # ä½¿ç”¨ç›¸å…³è¯
        'one', 'two', 'three', 'first', 'second',  # æ•°å­—ç›¸å…³è¯
        'the', 'and', 'for', 'that', 'this', 'with',  # å¸¸è§åœç”¨è¯
        'was', 'is', 'are', 'were', 'been', 'be', 'have'
    }
    
    # æ›´æ–°æƒ…æ„Ÿè¯å…¸
    positive_words.update(product_specific_positive)
    negative_words.update(product_specific_negative)
    
    # ç§»é™¤æ­§ä¹‰è¯å’Œåœç”¨è¯
    positive_words = positive_words - ambiguous_words - stop_words
    negative_words = negative_words - ambiguous_words - stop_words
    
    # åˆ†è¯å¹¶è¿‡æ»¤
    words = text.lower().split()
    if sentiment_type == 'positive':
        filtered_words = [word for word in words 
                         if word in positive_words]
        colormap = 'YlGn'
    else:
        filtered_words = [word for word in words 
                         if word in negative_words]
        colormap = 'RdPu'
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æƒ…æ„Ÿè¯ï¼Œè¿”å›ç©ºå›¾
    if not filtered_words:
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.text(0.5, 0.5, 'No significant sentiment words found',
                ha='center', va='center')
        ax.axis('off')
        return fig
    
    # ç”Ÿæˆè¯äº‘
    text = ' '.join(filtered_words)
    wordcloud = WordCloud(
        width=800,
        height=400,
        background_color='white',
        colormap=colormap,
        max_words=30,
        min_font_size=12,
        max_font_size=160,
        prefer_horizontal=0.7
    ).generate(text)
    
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    ax.set_title(title)
    return fig

def get_top_sentiment_words(text, sentiment_type='positive', n=10):
    """è·å–å‰Nä¸ªæœ€å¸¸è§çš„æƒ…æ„Ÿè¯"""
    # è·å–æƒ…æ„Ÿè¯å…¸
    positive_words = set(opinion_lexicon.positive())
    negative_words = set(opinion_lexicon.negative())
    
    # äº§å“è¯„è®ºç‰¹å®šçš„ç§¯æè¯
    product_specific_positive = {
        'affordable', 'worth', 'sturdy', 'durable', 'reliable', 
        'fast', 'quick', 'solid', 'perfect', 'excellent',
        'strong', 'stable', 'premium', 'professional', 'recommended',
        'satisfied', 'quality', 'great', 'nice', 'good',
        'convenient', 'efficient', 'effective', 'impressive'
    }
    
    # äº§å“è¯„è®ºç‰¹å®šçš„æ¶ˆæè¯ï¼ˆåªä¿ç•™æ˜ç¡®çš„è´Ÿé¢è¯ï¼‰
    product_specific_negative = {
        'defective', 'faulty', 'broken', 'useless',
        'disappointing', 'terrible', 'horrible', 'awful',
        'worthless', 'poor-quality', 'unreliable', 'unstable',
        'overpriced', 'ineffective', 'malfunctioning'
    }
    
    # éœ€è¦ä»æƒ…æ„Ÿè¯å…¸ä¸­ç§»é™¤çš„æ­§ä¹‰è¯
    ambiguous_words = {
        'quality',    # å¯èƒ½è¡¨ç¤ºä¾¿å®œ(ç§¯æ)æˆ–åŠ£è´¨(æ¶ˆæ)
        'cheap',      # å¯èƒ½è¡¨ç¤ºä¾¿å®œ(ç§¯æ)æˆ–åŠ£è´¨(æ¶ˆæ)
        'hard',       # å¯èƒ½è¡¨ç¤ºåšç¡¬(ç§¯æ)æˆ–å›°éš¾(æ¶ˆæ)
        'emergency',  # æè¿°æƒ…å†µè€Œéäº§å“è´¨é‡
        'blame',      # æè¿°è¡Œä¸ºè€Œéäº§å“
        'basic',      # å¯èƒ½æ˜¯ä¸­æ€§æè¿°
        'simple',     # å¯èƒ½æ˜¯ç§¯ææˆ–æ¶ˆæ
        'just',       # é€šå¸¸æ˜¯ä¸­æ€§è¯
        'want',       # æ„æ„¿æè¿°
        'need',       # éœ€æ±‚æè¿°
        'try',        # è¡Œä¸ºæè¿°
        'return',     # è¡Œä¸ºæè¿°
        'cost',       # ä»·æ ¼æè¿°
        'price',      # ä»·æ ¼æè¿°
        'charge'      # å¯èƒ½æ˜¯å……ç”µæˆ–æ”¶è´¹
    }
    
    # é¢å¤–çš„åœç”¨è¯
    extra_stop_words = {
        'issues', 'issue', 'problem', 'problems',  # ä¸­æ€§è¯
        'like', 'well', 'better', 'works', 'work',  # ä¸­æ€§/æè¿°æ€§è¯
        'cable', 'charger', 'wire', 'cord', 'adapter',  # äº§å“ç›¸å…³è¯
        'time', 'month', 'day', 'year', 'week',  # æ—¶é—´ç›¸å…³è¯
        'amazon', 'product', 'purchase', 'bought', 'order',  # è´­ä¹°ç›¸å…³è¯
        'use', 'using', 'used', 'usage',  # ä½¿ç”¨ç›¸å…³è¯
        'one', 'two', 'three', 'first', 'second',  # æ•°å­—ç›¸å…³è¯
    }
    
    # æ›´æ–°æƒ…æ„Ÿè¯å…¸
    positive_words.update(product_specific_positive)
    negative_words.update(product_specific_negative)
    
    # ç§»é™¤æ‰€æœ‰æ­§ä¹‰è¯å’Œåœç”¨è¯
    positive_words = positive_words - ambiguous_words - extra_stop_words
    negative_words = negative_words - ambiguous_words - extra_stop_words
    
    # åˆ†è¯å¹¶è¿‡æ»¤
    words = text.lower().split()
    word_freq = {}
    target_words = positive_words if sentiment_type == 'positive' else negative_words
    
    for word in words:
        if word in target_words:
            word_freq[word] = word_freq.get(word, 0) + 1
    
    # è·å–å‰Nä¸ªæœ€å¸¸è§çš„è¯
    top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:n]
    return top_words

def main():
    # æ ‡é¢˜å’Œä»‹ç»
    st.title('ğŸ“Š Amazon Cable Products Pricing Analysis')
    st.markdown("""
    This dashboard provides comprehensive analysis of cable products pricing on Amazon India.
    Use the filters in the sidebar to explore different price ranges and product categories.
    """)
    
    # åŠ è½½æ•°æ®æ—¶æ˜¾ç¤ºè¿›åº¦æ¡
    with st.spinner('Loading data...'):
        df, features, analyzer = load_cached_data()
    
    # åˆ›å»ºä»·æ ¼å¼¹æ€§åˆ†æå™¨å®ä¾‹
    elasticity_analyzer = PriceElasticityAnalyzer()
    
    # ä¾§è¾¹æ ä¼˜åŒ–
    st.sidebar.image('https://upload.wikimedia.org/wikipedia/commons/4/4a/Amazon_icon.svg', width=100)
    st.sidebar.title('Analysis Controls')
    
    # ç®€åŒ–ä¾§è¾¹æ è®¾ç½®
    st.sidebar.markdown("---")
    st.sidebar.subheader("Price Elasticity Settings")
    
    # åªä¿ç•™å¼¹æ€§ç³»æ•°è®¡ç®—æ–¹æ³•é€‰æ‹©
    elasticity_method = st.sidebar.selectbox(
        'Calculation Method',
        ['Log-Log', 'Point', 'Arc'],
        help="Method to calculate price elasticity"
    )
    
    # æ·»åŠ æ›´å¤šç­›é€‰å™¨
    price_range = st.sidebar.slider(
        'Price Range (â‚¹)',
        float(df['discounted_price'].min()),
        float(df['discounted_price'].max()),
        (float(df['discounted_price'].min()), float(df['discounted_price'].max()))
    )
    
    rating_filter = st.sidebar.slider(
        'Minimum Rating',
        min_value=0.0,
        max_value=5.0,
        value=0.0,
        step=0.5
    )
    
    # æ•°æ®ç­›é€‰
    mask = (
        (df['discounted_price'] >= price_range[0]) & 
        (df['discounted_price'] <= price_range[1]) &
        (df['rating'] >= rating_filter)
    )
    filtered_df = df[mask]
    
    # æ·»åŠ åˆ·æ–°æŒ‰é’®
    if st.sidebar.button('Refresh Analysis'):
        try:
            st.rerun()
        except AttributeError:
            try:
                st.experimental_rerun()  # å…¼å®¹æ—§ç‰ˆæœ¬
            except AttributeError:
                st.error("Refresh functionality not available in this Streamlit version")
    
    # å¸‚åœºæ¦‚è§ˆä½¿ç”¨å¡ç‰‡å¼è®¾è®¡
    st.header('ğŸ“ˆ Market Overview')
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            'Total Products',
            len(filtered_df),
            delta=f"{len(filtered_df)-len(df)} from total"
        )
    with col2:
        st.metric(
            'Average Rating',
            f"{filtered_df['rating'].mean():.2f}",
            delta=f"{(filtered_df['rating'].mean() - df['rating'].mean()):.2f}"
        )
    with col3:
        st.metric(
            'Average Discount',
            f"{filtered_df['real_discount'].mean():.1f}%"
        )
    with col4:
        st.metric(
            'Price Range',
            f"â‚¹{filtered_df['discounted_price'].min():.0f} - â‚¹{filtered_df['discounted_price'].max():.0f}"
        )
    
    # ä½¿ç”¨tabsç»„ç»‡å†…å®¹
    tab1, tab2, tab3 = st.tabs(["Price Analysis", "Sentiment Analysis", "Product Rankings"])
    
    with tab1:
        # Price Analysis æ ‡ç­¾é¡µ
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader('Price Distribution')
            fig = px.histogram(
                filtered_df,
                x='discounted_price',
                nbins=30,
                title='Price Distribution',
                labels={'discounted_price': 'Price (â‚¹)', 'count': 'Count'},
                hover_data=['discounted_price'],
                opacity=0.7,  # è°ƒæ•´é€æ˜åº¦
            )
            
            # æ›´æ–°å›¾è¡¨å¸ƒå±€
            fig.update_layout(
                bargap=0.2,  # æ·»åŠ æŸ±å­ä¹‹é—´çš„é—´éš”
                plot_bgcolor='white',  # è®¾ç½®ç™½è‰²èƒŒæ™¯
                showlegend=False,
                xaxis=dict(
                    title='Price (â‚¹)',
                    gridcolor='lightgrey',
                    showgrid=True,
                    showline=True,
                    linewidth=1,
                    linecolor='black',
                    tickformat='â‚¹%d'
                ),
                yaxis=dict(
                    title='Number of Products',
                    gridcolor='lightgrey',
                    showgrid=True,
                    showline=True,
                    linewidth=1,
                    linecolor='black'
                ),
                margin=dict(l=40, r=40, t=40, b=40)  # è°ƒæ•´è¾¹è·
            )
            
            # æ›´æ–°æŸ±å­é¢œè‰²å’Œè¾¹æ¡†
            fig.update_traces(
                marker_color='rgb(30, 144, 255)',  # è®¾ç½®æŸ±å­é¢œè‰²ä¸ºæ·±è“è‰²
                marker_line_color='rgb(8, 48, 107)',  # è®¾ç½®è¾¹æ¡†é¢œè‰²
                marker_line_width=1  # è®¾ç½®è¾¹æ¡†å®½åº¦
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # æ·»åŠ ç›¸å…³æ€§åˆ†æ
            st.subheader('ğŸ“Š Correlation Analysis')
            correlation_matrix = filtered_df[
                ['discounted_price', 'rating', 'rating_count', 'real_discount']
            ].corr()
            
            labels = {
                'discounted_price': 'Price',
                'rating': 'Rating',
                'rating_count': 'Reviews',
                'real_discount': 'Discount'
            }
            
            fig = go.Figure(data=go.Heatmap(
                z=correlation_matrix,
                x=list(labels.values()),
                y=list(labels.values()),
                text=correlation_matrix.round(2),
                texttemplate='%{text}',
                textfont={"size": 10},
                hoverongaps=False,
                hovertemplate='%{x} vs %{y}<br>Correlation: %{z:.2f}<extra></extra>',
                colorscale='RdBu',
                zmid=0
            ))
            
            fig.update_layout(
                title='Correlation Matrix',
                height=400,
                hoverlabel=dict(bgcolor="white"),
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.subheader('Price Elasticity Analysis')
            
            # è®¡ç®—ä»·æ ¼å¼¹æ€§ç³»æ•°
            elasticity = elasticity_analyzer.calculate_elasticity(
                filtered_df['discounted_price'].values,
                filtered_df['rating_count'].values,
                method=elasticity_method
            )
            
            # æ˜¾ç¤ºå¼¹æ€§ç³»æ•°åŠå…¶å«ä¹‰
            st.metric('Price Elasticity', f"{elasticity:.2f}")
            
            if elasticity < 0.5:
                st.success("""
                **ä½ä»·æ ¼å¼¹æ€§** (< 0.5):
                - æ¶ˆè´¹è€…å¯¹ä»·æ ¼å˜åŒ–ä¸æ•æ„Ÿ
                - å¯ä»¥è€ƒè™‘é€‚å½“æé«˜ä»·æ ¼
                - é‡ç‚¹å…³æ³¨äº§å“è´¨é‡å’Œå“ç‰Œå»ºè®¾
                """)
            else:
                st.warning("""
                **é«˜ä»·æ ¼å¼¹æ€§** (â‰¥ 0.5):
                - æ¶ˆè´¹è€…å¯¹ä»·æ ¼å˜åŒ–æ•æ„Ÿ
                - éœ€è¦è°¨æ…è°ƒæ•´ä»·æ ¼
                - å…³æ³¨ç«å“å®šä»·ç­–ç•¥
                """)
            
            # æ ¹æ®ä¸åŒçš„è®¡ç®—æ–¹æ³•æ˜¾ç¤ºä¸åŒçš„ä»·æ ¼-éœ€æ±‚å…³ç³»å›¾
            if elasticity_method == 'Log-Log':
                # å¯¹æ•°è½¬æ¢åçš„æ•£ç‚¹å›¾
                fig = px.scatter(
                    filtered_df,
                    x=np.log(filtered_df['discounted_price']),
                    y=np.log(filtered_df['rating_count']),
                    title='Log-Log Price vs Demand',
                    labels={
                        'x': 'Log Price',
                        'y': 'Log Demand'
                    },
                    trendline="ols"
                )
            elif elasticity_method == 'Point':
                # åˆ†æ®µç‚¹å¼¹æ€§å›¾
                fig = px.scatter(
                    filtered_df,
                    x='discounted_price',
                    y='rating_count',
                    title='Point Price Elasticity',
                    labels={
                        'discounted_price': 'Price (â‚¹)',
                        'rating_count': 'Demand (Reviews)'
                    }
                )
                # æ·»åŠ åˆ†æ®µç‚¹å¼¹æ€§çº¿
                sorted_df = filtered_df.sort_values('discounted_price')
                segments = np.array_split(sorted_df, 5)
                for segment in segments:
                    fig.add_trace(go.Scatter(
                        x=segment['discounted_price'],
                        y=segment['rating_count'],
                        mode='lines',
                        name=f'Segment {len(fig.data)}'
                    ))
            else:  # Arc
                # å¼§å¼¹æ€§å›¾
                fig = px.scatter(
                    filtered_df,
                    x='discounted_price',
                    y='rating_count',
                    title='Arc Price Elasticity',
                    labels={
                        'discounted_price': 'Price (â‚¹)',
                        'rating_count': 'Demand (Reviews)'
                    },
                    trendline="lowess"  # ä½¿ç”¨å±€éƒ¨åŠ æƒå›å½’
                )
            
            st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        st.header('ğŸ“ Review Analysis')
        
        # 1. æƒ…æ„Ÿåˆ†å¸ƒæŒ‡æ ‡
        total_reviews = len(df)
        positive_count = (df['sentiment'] == 1.0).sum()
        neutral_count = (df['sentiment'] == 0.0).sum()
        negative_count = (df['sentiment'] == -1.0).sum()
        
        positive_ratio = (positive_count / total_reviews) * 100
        neutral_ratio = (neutral_count / total_reviews) * 100
        negative_ratio = (negative_count / total_reviews) * 100
        
        st.markdown("### è¯„è®ºæƒ…æ„Ÿåˆ†å¸ƒ")
        metric_cols = st.columns(3)
        
        with metric_cols[0]:
            st.metric(
                "ç§¯æè¯„è®º",
                f"{positive_ratio:.1f}%",
                f"{positive_count} æ¡è¯„è®º"
            )
        
        with metric_cols[1]:
            st.metric(
                "ä¸­æ€§è¯„è®º",
                f"{neutral_ratio:.1f}%",
                f"{neutral_count} æ¡è¯„è®º"
            )
        
        with metric_cols[2]:
            st.metric(
                "æ¶ˆæè¯„è®º",
                f"{negative_ratio:.1f}%",
                f"{negative_count} æ¡è¯„è®º"
            )
        
        # 2. æƒ…æ„Ÿè¯åˆ†æ
        st.markdown("### æƒ…æ„Ÿè¯åˆ†æ")
        
        # è·å–æ­£é¢å’Œè´Ÿé¢è¯„è®ºçš„æ–‡æœ¬
        positive_text = ' '.join(df[df['sentiment'] == 1.0]['review_content'].astype(str))
        negative_text = ' '.join(df[df['sentiment'] == -1.0]['review_content'].astype(str))
        
        # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ç§¯æè¯„è®ºå…³é”®è¯")
            # è¯äº‘å›¾
            if positive_text:
                fig_pos = create_wordcloud(positive_text, "Positive Reviews", 'positive')
                st.pyplot(fig_pos)
            
            # ç§¯ææƒ…æ„Ÿè¯é¢‘ç‡ç›´æ–¹å›¾
            top_positive = get_top_sentiment_words(positive_text, 'positive', 10)
            if top_positive:
                # åˆ›å»ºæ¸å˜ç»¿è‰²ï¼ˆé¢‘æ¬¡é«˜çš„é¢œè‰²æ›´æ·±ï¼‰
                n_bars = len(top_positive)
                green_colors = [
                    f'rgba(40, {200 - i * 15}, 40, {1 - i * 0.05})'  # ä»æ·±åˆ°æµ…çš„ç»¿è‰²
                    for i in range(n_bars)
                ]
                
                fig_pos_freq = go.Figure()
                fig_pos_freq.add_trace(go.Bar(
                    x=[word for word, _ in top_positive],  # ä¸éœ€è¦åè½¬ï¼Œä¿æŒåŸæœ‰é¡ºåºï¼ˆé¢‘æ¬¡ä»é«˜åˆ°ä½ï¼‰
                    y=[freq for _, freq in top_positive],
                    marker_color=green_colors,  # é¢œè‰²åˆ—è¡¨ä»æ·±åˆ°æµ…
                    hovertemplate='è¯è¯­: %{x}<br>é¢‘æ¬¡: %{y}<extra></extra>'
                ))
                
                fig_pos_freq.update_layout(
                    title="Top 10 Positive Words",
                    xaxis_title="Words",
                    yaxis_title="Frequency",
                    showlegend=False,
                    xaxis_tickangle=-45,
                    height=400,
                    plot_bgcolor='white',
                    yaxis=dict(gridcolor='rgba(0,0,0,0.1)'),
                    margin=dict(l=50, r=20, t=50, b=80)
                )
                st.plotly_chart(fig_pos_freq)
        
        with col2:
            st.markdown("#### æ¶ˆæè¯„è®ºå…³é”®è¯")
            # è¯äº‘å›¾
            if negative_text:
                fig_neg = create_wordcloud(negative_text, "Negative Reviews", 'negative')
                st.pyplot(fig_neg)
            
            # æ¶ˆææƒ…æ„Ÿè¯é¢‘ç‡ç›´æ–¹å›¾
            top_negative = get_top_sentiment_words(negative_text, 'negative', 10)
            if top_negative:
                # åˆ›å»ºæ¸å˜çº¢è‰²ï¼ˆé¢‘æ¬¡é«˜çš„é¢œè‰²æ›´æ·±ï¼‰
                n_bars = len(top_negative)
                red_colors = [
                    f'rgba({255 - i * 10}, {20 + i * 5}, {20 + i * 5}, {1 - i * 0.05})'  # ä»æ·±åˆ°æµ…çš„çº¢è‰²
                    for i in range(n_bars)
                ]
                
                fig_neg_freq = go.Figure()
                fig_neg_freq.add_trace(go.Bar(
                    x=[word for word, _ in top_negative],  # ä¸éœ€è¦åè½¬ï¼Œä¿æŒåŸæœ‰é¡ºåºï¼ˆé¢‘æ¬¡ä»é«˜åˆ°ä½ï¼‰
                    y=[freq for _, freq in top_negative],
                    marker_color=red_colors,  # é¢œè‰²åˆ—è¡¨ä»æ·±åˆ°æµ…
                    hovertemplate='è¯è¯­: %{x}<br>é¢‘æ¬¡: %{y}<extra></extra>'
                ))
                
                fig_neg_freq.update_layout(
                    title="Top 10 Negative Words",
                    xaxis_title="Words",
                    yaxis_title="Frequency",
                    showlegend=False,
                    xaxis_tickangle=-45,
                    height=400,
                    plot_bgcolor='white',
                    yaxis=dict(gridcolor='rgba(0,0,0,0.1)'),
                    margin=dict(l=50, r=20, t=50, b=80)
                )
                st.plotly_chart(fig_neg_freq)
        
        # 3. è¯„åˆ†åˆ†å¸ƒï¼ˆç§»åˆ°æœ€ä¸‹é¢ï¼‰
        st.markdown("### è¯„åˆ†åˆ†å¸ƒ")
        rating_counts = df['rating'].value_counts().sort_index()
        fig_rating = go.Figure()
        
        # æ·»åŠ æŸ±çŠ¶å›¾
        fig_rating.add_trace(go.Bar(
            x=rating_counts.index,
            y=rating_counts.values,
            marker_color='rgb(0, 123, 255)',
            hovertemplate='è¯„åˆ†: %{x}<br>æ•°é‡: %{y}<extra></extra>'
        ))
        
        # æ›´æ–°å¸ƒå±€
        fig_rating.update_layout(
            title={
                'text': 'è¯„åˆ†åˆ†å¸ƒ',
                'y': 0.9,
                'x': 0.5,
                'xanchor': 'center',
                'yanchor': 'top'
            },
            xaxis=dict(
                title='è¯„åˆ†',
                tickmode='array',
                ticktext=['1', '2', '3', '4', '5'],
                tickvals=[1, 2, 3, 4, 5],
                tickangle=0,
                gridcolor='rgba(0,0,0,0.1)',
                showgrid=True
            ),
            yaxis=dict(
                title='è¯„è®ºæ•°é‡',
                gridcolor='rgba(0,0,0,0.1)',
                showgrid=True
            ),
            plot_bgcolor='white',
            showlegend=False,
            height=400,
            margin=dict(l=50, r=50, t=80, b=50),
            bargap=0.2
        )
        
        # æ·»åŠ å¹³å‡è¯„åˆ†æ ‡æ³¨
        avg_rating = df['rating'].mean()
        fig_rating.add_vline(
            x=avg_rating,
            line_dash="dash",
            line_color="red",
            annotation_text=f"å¹³å‡è¯„åˆ†: {avg_rating:.2f}",
            annotation_position="top"
        )
        
        st.plotly_chart(fig_rating, use_container_width=True)
    
    with tab3:
        st.subheader('Top Rated Products')
        top_products = filtered_df.nlargest(10, 'rating')[
            ['product_name', 'discounted_price', 'rating', 'rating_count']
        ].reset_index(drop=True)
        
        # ä½¿ç”¨æ›´å¥½çš„è¡¨æ ¼å±•ç¤º
        st.dataframe(
            top_products,
            column_config={
                "product_name": "Product Name",
                "discounted_price": st.column_config.NumberColumn(
                    "Price (â‚¹)",
                    format="â‚¹%.2f"
                ),
                "rating": st.column_config.NumberColumn(
                    "Rating",
                    format="%.1f â­"
                ),
                "rating_count": st.column_config.NumberColumn(
                    "Reviews",
                    format="%d ğŸ“"
                )
            },
            hide_index=True,
            use_container_width=True
        )
    
    # ç§»é™¤é¡µé¢åº•éƒ¨çš„ç›¸å…³æ€§çŸ©é˜µ
    # åªä¿ç•™é¡µè„š
    st.markdown("""---""")
    st.markdown("""
        <div style='text-align: center'>
            <p>Made with â¤ï¸ by Yanzhen Chen | Data last updated: 2025</p>
        </div>
    """, unsafe_allow_html=True)

# åŠ è½½æ•°æ®
@st.cache_data
def load_cached_data():
    df = load_data('amazon.csv')
    features = extract_features(df)
    
    # æƒ…æ„Ÿåˆ†æ
    analyzer = SentimentAnalyzer()
    df = analyzer.analyze_reviews(df)
    
    return df, features, analyzer

if __name__ == '__main__':
    main() 